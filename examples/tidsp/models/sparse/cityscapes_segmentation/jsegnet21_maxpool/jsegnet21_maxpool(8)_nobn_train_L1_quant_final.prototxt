#Sover parameters
test_iter: 200
test_interval: 2000
test_initialization: true
display: 100

type: "Adam"
base_lr: 1e-5

lr_policy: "fixed"
gamma: 0.1
max_iter: 4000 #32000
momentum: 0.9

weight_decay: 1e-5
regularization_type: "L1"

snapshot: 1000
snapshot_prefix: "training/jsegnet21_maxpool_L1_nobn_quant_final"
solver_mode: GPU
random_seed: 33

snapshot_log: true
#ignore_mismatching_blobs: true

display_sparsity: 1000
sparse_mode: SPARSE_UPDATE


insert_quantization_param: true
quantization_start_iter: 2000

#Net parameters
net_param {

name: "JSegNet21-MaxPool-(8)"

layer {
  name: "data"
  type: "ImageLabelListData"
  top: "data"
  top: "label"
  include {  phase: TRAIN  }
  transform_param {
    crop_size: 640
    ##mirror: true    
    ##mean_value: 128
    ##mean_value: 128
    ##mean_value: 128
    #num_labels: 5
    #display: true
  }
  image_label_data_param {    
    image_list_path: "data/train-image-list.txt"
    label_list_path: "data/train-label-list.txt"
    batch_size: 16
    shuffle: true 
    #label_slice {
    #  dim: 640
    #  dim: 640
    #  stride: 1
    #  stride: 1
    #  offset: 0
    #  offset: 0
    #}
    #padding: REFLECT
    #backend: LMDB
        
    #Min and Max sizes. This will be applied before the rest of the processing.
    #Setting both of these may cause distortion of the image. Recommed to set only one of these or a large range.
    #size_min: 512    
    #size_max: 2048   
    
    #Random scaling before crop. This will be applied before cropping
    scale_prob: 0.5
    scale_min: 0.75
    scale_max: 1.25    
    
    #Set to 1 to disable multireaded read      
    #threads: 1           
  }
}

layer {
  name: "data"
  type: "ImageLabelListData"
  top: "data"
  top: "label"
  include {  phase: TEST  }
  transform_param {
    crop_size: 640
    mirror: false       
    #mean_value: 128
    #mean_value: 128
    #mean_value: 128
  }
  image_label_data_param {    
    image_list_path: "data/val-image-list.txt"
    label_list_path: "data/val-label-list.txt"
    
    batch_size: 4
    shuffle: false
    #label_slice {
    #  dim: 640
    #  dim: 640
    #  stride: 1
    #  stride: 1
    #  offset: 0
    #  offset: 0
    #}
    #padding: REFLECT
    #backend: LMDB

    #Set to 1 to disable multireaded read      
    #threads: 1  
  }
}

layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}

layer {
  name: "conv1a"
  bottom: "data/bias"
  top: "conv1a"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 32
    kernel_size: 5
    pad: 2
    stride: 2
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 1    
    group: 1
  }
}
layer {
  name: "conv1a/bn"
  bottom: "conv1a"
  top: "conv1a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}
layer {
  name: "conv1a/relu"
  bottom: "conv1a"
  top: "conv1a"
  type: "ReLU"
}
layer {
  name: "conv1b"
  bottom: "conv1a"
  top: "conv1b"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 32
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 1    
    group: 4 #1
  }
}
layer {
  name: "conv1b/bn"
  bottom: "conv1b"
  top: "conv1b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}  

layer {
  name: "conv1b/relu"
  bottom: "conv1b"
  top: "conv1b"
  type: "ReLU"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  bottom: "pool1"
  top: "res2a_branch2a"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 1    
    group: 1 #4
  }
}
layer {
  name: "res2a_branch2a/bn"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}   

layer {
  name: "res2a_branch2a/relu"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  type: "ReLU"
}
layer {
  name: "res2a_branch2b"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 1    
    group: 4
  }
}
layer {
  name: "res2a_branch2b/bn"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}    

layer {
  name: "res2a_branch2b/relu"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  type: "ReLU"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  bottom: "pool2"
  top: "res3a_branch2a"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 1    
    group: 1 #4
  }
}
layer {
  name: "res3a_branch2a/bn"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}     

layer {
  name: "res3a_branch2a/relu"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  type: "ReLU"
}
layer {
  name: "res3a_branch2b"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 1    
    group: 4
  }
}
layer {
  name: "res3a_branch2b/bn"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}  

layer {
  name: "res3a_branch2b/relu"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  type: "ReLU"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  bottom: "pool3"
  top: "res4a_branch2a"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 1    
    group: 1 #4
  }
}
layer {
  name: "res4a_branch2a/bn"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}    

layer {
  name: "res4a_branch2a/relu"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  type: "ReLU"
}
layer {
  name: "res4a_branch2b"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 1    
    group: 4
  }
}
layer {
  name: "res4a_branch2b/bn"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}    

layer {
  name: "res4a_branch2b/relu"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  type: "ReLU"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1 #setting kernel to 1, to disable this max pooling as it may hurt segmentation
    stride: 1      #setting stride to 1, to increase resolution
  }
}
layer {
  name: "res5a_branch2a"
  bottom: "pool4"
  top: "res5a_branch2a"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 2   
    group: 1 #4
  }
}
layer {
  name: "res5a_branch2a/bn"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}    

layer {
  name: "res5a_branch2a/relu"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  type: "ReLU"
}
layer {
  name: "res5a_branch2b"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  type: "Convolution"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }  
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 2
    stride: 1
    bias_term: true
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }    
    dilation: 2    
    group: 4
  }
}
layer {
  name: "res5a_branch2b/bn"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}    

layer {
  name: "res5a_branch2b/relu"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  type: "ReLU"
}

#------------------------------------------------------
#Output layers
#------------------------------------------------------
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }    
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 4
    bias_term: true    
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 } 
    dilation: 4
    group: 2 
  }  
}
layer {
  name: "out5a/bn"
  bottom: "out5a"
  top: "out5a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"  
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }    
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param { lr_mult: 1 decay_mult: 1 }
  param { lr_mult: 2 decay_mult: 0 }    
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    bias_term: true    
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 } 
    dilation: 1
    group: 2
  }  
}
layer {
  name: "out3a/bn"
  bottom: "out3a"
  top: "out3a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
  type: "Eltwise"
}

#----------------------------------------------------------------------------
#Additional ctx layers
#----------------------------------------------------------------------------
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param { lr_mult: 1 decay_mult: 1.0 }
  param { lr_mult: 2 decay_mult: 0 }    
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    bias_term: true       
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }  
    dilation: 1
    group: 1     
  }  
}

layer {
  name: "ctx_conv1/bn"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}

layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}

layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param { lr_mult: 1 decay_mult: 1.0 }
  param { lr_mult: 2 decay_mult: 0 }    
  convolution_param {
    num_output: 64
    pad: 4
    kernel_size: 3
    bias_term: true       
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 } 
    dilation: 4
    group: 1     
  } 
}

layer {
  name: "ctx_conv2/bn"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}

layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2" 
}

layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param { lr_mult: 1 decay_mult: 1.0 }
  param { lr_mult: 2 decay_mult: 0 }    
  convolution_param {
    num_output: 64
    pad: 4
    kernel_size: 3
    bias_term: true       
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 } 
    dilation: 4
    group: 1      
  }
}

layer {
  name: "ctx_conv3/bn"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}


layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}

layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param { lr_mult: 1 decay_mult: 1.0 }
  param { lr_mult: 2 decay_mult: 0 }    
  convolution_param {
    num_output: 64
    pad: 4
    kernel_size: 3
    bias_term: true       
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 } 
    dilation: 4
    group: 1        
  }  
}

layer {
  name: "ctx_conv4/bn"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001 
    scale_bias: true   
  }
}

layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"  
}

layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param { lr_mult: 1 decay_mult: 1.0 }
  param { lr_mult: 2 decay_mult: 0 }    
  convolution_param {
    num_output: 20
    kernel_size: 3
    pad: 1
    bias_term: true       
    weight_filler { type: "msra" }
    bias_filler { type: "constant" value: 0 }   
    dilation: 1   
    group: 1      
  }   
}



layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"     
}

#--------------------------------------------
#Final deconvolution layers
#--------------------------------------------
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }    
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }    
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 20
    stride: 2
    weight_filler {
      type: "bilinear"
    }    
  }
}
#----
layer {
  name: "ctx_final_score"
  type: "Crop"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "ctx_final_score"
  crop_param {
    axis: 2
    offset: 0
  }
}

#--------------------------------------------
#Score/Loss/Accuracy of final layer 
#--------------------------------------------
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ctx_final_score"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
  accuracy_param {
    ignore_label: 255
  }    
}


layer {
  name: "pixel_accuracy/top-1"
  type: "Accuracy"
  bottom: "ctx_final_score"
  bottom: "label"
  top: "pixel_accuracy/top-1"
  accuracy_param {
    ignore_label: 255
  }  
  include {
    phase: TEST
  }
}

}


